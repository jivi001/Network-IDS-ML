# ğŸ›¡ï¸ Network Intrusion Detection System (NIDS)

A **production-grade Hybrid Machine Learning system** for detecting network intrusions. Combines a supervised Random Forest for known attacks with an Isolation Forest for zero-day anomaly detection.

---

## âœ¨ Key Features

- **Hybrid Two-Tier Architecture** â€” Supervised + unsupervised detection cascade
- **Multi-Dataset Support** â€” NSL-KDD and UNSW-NB15 (plug-in architecture for more)
- **SMOTE Balancing** â€” Handles class imbalance in real-world traffic data
- **SHAP Explainability** â€” Understand why each prediction was made
- **REST API** â€” Deploy as a microservice with Docker
- **YAML Config-Driven** â€” Fully configurable without touching code

---

## ğŸ§  How It Works

```mermaid
flowchart TD
    A["ğŸŒ Network Traffic"] --> B["âš™ï¸ Preprocessing
Clean Â· Encode Â· Scale"]
    B --> C["ğŸ” Feature Selection
importance / RFE â€” Top-N features"]
    C --> D["ğŸŒ² Tier 1: Random Forest
Known Attack Classification"]
    D -- "âš¡ Attack detected" --> E["ğŸš¨ ALERT â€” Known Attack"]
    D -- "âœ… Classified as Normal" --> F["ğŸï¸ Tier 2: Isolation Forest
Zero-Day Anomaly Detection"]
    F -- "ğŸ”´ Anomaly" --> G["ğŸš¨ ALERT â€” Zero-Day Attack"]
    F -- "ğŸŸ¢ Normal" --> H["âœ… PASS â€” Benign Traffic"]
```

---

## ğŸ“Š Performance

| Dataset       | Recall    | Precision | F1-Score  | Attack Detection Rate |
| ------------- | --------- | --------- | --------- | --------------------- |
| NSL-KDD       | 72.4%     | 82.5%     | 70.8%     | 68.3%                 |
| **UNSW-NB15** | **95.2%** | **100%**  | **97.5%** | **100%**              |

> Results from default configuration. UNSW-NB15 is the **recommended dataset** for production use.

---

## ğŸš€ Quick Start

### 1. Install

```powershell
git clone https://github.com/jivi001/Network-IDS-ML.git
cd Network-IDS-ML

# Create and activate virtual environment
python -m venv nids_env
nids_env\Scripts\activate      # Windows
# source nids_env/bin/activate  # Linux/Mac

pip install -r requirements.txt
```

### 2. Download Dataset

```powershell
# Automated download (NSL-KDD public mirror)
python scripts/download_data.py --dataset nsl-kdd

# UNSW-NB15 (will prompt with manual download link as it requires registration)
python scripts/download_data.py --dataset unsw-nb15
```

Or place files manually in `data/raw/`.

### 3. Train

```powershell
# UNSW-NB15 (recommended)
python scripts/train.py --config configs/training/unsw_nb15.yaml

# NSL-KDD (default)
python scripts/train.py --config configs/training/default.yaml

# NSL-KDD (optimized hyperparameters)
python scripts/train.py --config configs/training/optimized.yaml
```

Results are saved to `experiments/runs/<experiment_id>/`.

### 4. Evaluate

```powershell
python scripts/evaluate.py \
  --model "experiments/runs/<experiment_id>/models" \
  --dataset "data/raw/unsw_nb15_test.csv" \
  --dataset-type unsw_nb15
```

---

## ğŸ“ Project Structure

```
Network-IDS-ML/
â”œâ”€â”€ nids/                        # Core Python package
â”‚   â”œâ”€â”€ data/                    # Data loading & validation
â”‚   â”œâ”€â”€ preprocessing/           # Cleaning, scaling, SMOTE
â”‚   â”œâ”€â”€ features/                # Feature selection (RFE / importance)
â”‚   â”œâ”€â”€ models/                  # Random Forest, Isolation Forest, Hybrid
â”‚   â”œâ”€â”€ evaluation/              # Metrics & plots
â”‚   â”œâ”€â”€ explainability/          # SHAP interpretability
â”‚   â”œâ”€â”€ pipelines/               # Training / evaluation / inference
â”‚   â””â”€â”€ utils/                   # Config & logging helpers
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ datasets/                # nsl_kdd.yaml, unsw_nb15.yaml
â”‚   â”œâ”€â”€ models/                  # RF & iForest hyperparameters
â”‚   â””â”€â”€ training/                # default.yaml, optimized.yaml, unsw_nb15.yaml
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data/                    # Dataset preparation scripts
â”‚   â”‚   â””â”€â”€ prepare_unsw_nb15.py
â”‚   â”œâ”€â”€ train.py                 # Training CLI
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation CLI
â”‚   â””â”€â”€ cross_dataset_eval.py   # Cross-dataset benchmarking
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ Dockerfile               # python:3.11-slim
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ inference_api.py         # FastAPI REST API (Swagger at /docs)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Original dataset files (git-ignored)
â”‚   â”‚   â”œâ”€â”€ UNSW-NB15/           # Raw UNSW-NB15 CSVs
â”‚   â”‚   â”œâ”€â”€ nsl_kdd_train.csv
â”‚   â”‚   â””â”€â”€ nsl_kdd_test.csv
â”‚   â”œâ”€â”€ processed/               # Preprocessed data (.gitkeep)
â”‚   â””â”€â”€ interim/                 # Intermediate files (.gitkeep)
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ runs/                    # Auto-generated per-run outputs (.gitkeep)
â”œâ”€â”€ models/                      # Promoted production models (.gitkeep)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_models.py
â”‚   â”‚   â”œâ”€â”€ test_inference.py
â”‚   â”‚   â””â”€â”€ test_preprocessor.py
â”‚   â””â”€â”€ integration/
â”‚       â””â”€â”€ test_api.py
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml               # Lint + test + Docker build
â”œâ”€â”€ .env.example                 # Environment variable template
â”œâ”€â”€ docs/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ pytest.ini
â””â”€â”€ README.md
```

---

## âš™ï¸ Configuration

All configs live in `configs/`. Key training options in any `configs/training/*.yaml`:

| Key                            | Description                                          |
| ------------------------------ | ---------------------------------------------------- |
| `feature_selection.method`     | `importance` (fast) or `rfe` (slower, more accurate) |
| `feature_selection.n_features` | Number of top features to use                        |
| `preprocessing.apply_smote`    | `true`/`false` â€” enable class balancing              |
| `evaluation.compute_shap`      | `true`/`false` â€” SHAP feature importance plots       |

---

## ğŸ³ Docker Deployment

```powershell
cd deployment
docker-compose up --build
```

API will be available at `http://localhost:8000`.

- **Swagger UI**: http://localhost:8000/docs
- **Health check**: http://localhost:8000/health

See [DEPLOYMENT_GUIDE.md](docs/DEPLOYMENT_GUIDE.md) for full API reference.

---

## ğŸ“– Documentation

| Doc                                             | Description           |
| ----------------------------------------------- | --------------------- |
| [GETTING_STARTED.md](docs/GETTING_STARTED.md)   | Beginner's guide      |
| [TRAINING_GUIDE.md](docs/TRAINING_GUIDE.md)     | Training walkthrough  |
| [DEPLOYMENT_GUIDE.md](docs/DEPLOYMENT_GUIDE.md) | Production deployment |
| [DOCKER_GUIDE.md](docs/DOCKER_GUIDE.md)         | Docker setup          |
| [API_REFERENCE.md](docs/API_REFERENCE.md)       | Full API docs         |

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE).

---

## ğŸ“§ Contact

- **GitHub**: [@jivi001](https://github.com/jivi001)
- **Email**: jiviteshgd28@gmail.com
- **Issues**: [GitHub Issues](https://github.com/jivi001/Network-IDS-ML/issues)

---

## ğŸ™ Acknowledgments

- [NSL-KDD Dataset](https://www.unb.ca/cic/datasets/nsl.html) â€” University of New Brunswick
- [UNSW-NB15 Dataset](https://research.unsw.edu.au/projects/unsw-nb15-dataset) â€” UNSW Canberra
- [scikit-learn](https://scikit-learn.org/) community
